{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71a87b8-f03c-4168-869e-05ce0d0fac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from joblib import dump\n",
    "import os\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import time\n",
    "import onnxruntime as rt\n",
    "from onnxruntime.quantization import quantize_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76871441-eaf2-4d71-a5cf-5ae08ac3ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 5s 4ms/step - loss: 0.4890 - accuracy: 0.7911 - val_loss: 0.4649 - val_accuracy: 0.8090\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4476 - accuracy: 0.8167 - val_loss: 0.4536 - val_accuracy: 0.8163\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4395 - accuracy: 0.8183 - val_loss: 0.4509 - val_accuracy: 0.8169\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4344 - accuracy: 0.8203 - val_loss: 0.4517 - val_accuracy: 0.8135\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4319 - accuracy: 0.8208 - val_loss: 0.4476 - val_accuracy: 0.8173\n",
      "188/188 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4687\n",
      "           1       0.63      0.37      0.47      1313\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.74      0.66      0.68      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "[[4403  284]\n",
      " [ 824  489]]\n",
      "Модель PKL успешно создана в C:\\Users\\BMakunin\\SF\\mlops\\MLOps_1\\models\\NN.pkl\n",
      "Модель ONNX успешно создана в C:\\Users\\BMakunin\\SF\\mlops\\MLOps_1\\models\\NN.onnx\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "188/188 [==============================] - 0s 2ms/step\n",
      "Среднее время инференса оригинальной модели: 0.73362 секунд.\n",
      "Среднее время инференса ONNX-модели: 0.00469 секунд.\n",
      "188/188 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя квадратичная ошибка между двумя версиями модели: 9.457804717616803e-16\n",
      "Модели успешно конвертированы и работают одинаково.\n",
      "1.20.1\n",
      "Среднее время инференса ONNX: 0.00469 секунд.\n",
      "Среднее время инференса ONNX Quant: 0.00741 секунд.\n"
     ]
    }
   ],
   "source": [
    "# Определяем запуск только из скрипта\n",
    "if __name__ == \"__main__\":\n",
    "    # Загружаем данные из CSV-файла\n",
    "    data = pd.read_csv(os.path.abspath(\"../data/raw/UCI_Credit_Card.csv\"))\n",
    "    \n",
    "    # Выбираем признаки и целевую переменную\n",
    "    features = data.drop(columns=['ID', 'default.payment.next.month'])\n",
    "    target = data['default.payment.next.month']\n",
    "    \n",
    "    # Разделяем данные на тренировочную и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Нормализуем признаки\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Создаем простую нейросеть\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(16, activation='relu'),\n",
    "        # Бинарная классификация\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Компилируем модель\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Обучаем модель\n",
    "    epoch = 5\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=epoch, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    # Проверяем качество модели на тестовых данных\n",
    "    y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Сохраняем модель в формате pkl\n",
    "    model_file = os.path.abspath(\"../models/NN.pkl\")\n",
    "    dump(model, model_file)\n",
    "    print(f\"Модель PKL успешно создана в {model_file}\")\n",
    "\n",
    "    # Экспортируем модель в формат ONNX\n",
    "    onnx_model_file = os.path.abspath(\"../models/NN.onnx\")\n",
    "    onnx_model, _ = tf2onnx.convert.from_keras(model, output_path=onnx_model_file)\n",
    "    print(f\"Модель ONNX успешно создана в {onnx_model_file}\")\n",
    "\n",
    "    # Сравним показатели\n",
    "    # Измеряем время инференса обычной модели\n",
    "    # Количество проверок\n",
    "    cnt_reload = 10\n",
    "    start_time = time.time()\n",
    "    for _ in range(cnt_reload):\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "    inference_time_original = (time.time() - start_time) / cnt_reload\n",
    "    print(f\"Среднее время инференса оригинальной модели: {inference_time_original:.5f} секунд.\")\n",
    "\n",
    "    # Загружаем сессию ONNX Runtime\n",
    "    session = rt.InferenceSession(onnx_model_file)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    # Измеряем время инференса ONNX-модели\n",
    "    start_time_onnx = time.time()\n",
    "    for _ in range(cnt_reload):\n",
    "        onnx_predictions = session.run(None, {input_name: X_test_scaled.astype(np.float32)})\n",
    "    inference_time_onnx = (time.time() - start_time_onnx) / cnt_reload\n",
    "    print(f\"Среднее время инференса ONNX-модели: {inference_time_onnx:.5f} секунд.\")\n",
    "\n",
    "    # Проверка сходимости\n",
    "    # Предсказываем оригиналом\n",
    "    original_predictions = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Предсказываем через ONNX\n",
    "    onnx_predictions = session.run(None, {input_name: X_test_scaled.astype(np.float32)})[0]\n",
    "    \n",
    "    # Сравниваем результаты\n",
    "    mse_error = np.mean((original_predictions - onnx_predictions)**2)\n",
    "    print(f\"Средняя квадратичная ошибка между двумя версиями модели: {mse_error}\")\n",
    "    \n",
    "    if mse_error < 1e-6:\n",
    "        print(\"Модели успешно конвертированы и работают одинаково.\")\n",
    "    else:\n",
    "        print(\"Ошибка превышает допустимый порог, возможно проблема с конвертацией.\")\n",
    "    print(rt.__version__)\n",
    "\n",
    "    # Выполняем квантизацию модели\n",
    "    onnx_quantized_model_file = os.path.abspath('../models/NN_quant.onnx')\n",
    "    quantize_dynamic(onnx_model_file, onnx_quantized_model_file)\n",
    "\n",
    "    # Сравним показатели\n",
    "    print(f\"Среднее время инференса ONNX: {inference_time_onnx:.5f} секунд.\")\n",
    "\n",
    "    # Загружаем сессию ONNX Quant\n",
    "    session = rt.InferenceSession(onnx_quantized_model_file)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    # Измеряем время инференса ONNX\n",
    "    start_time_onnx = time.time()\n",
    "    for _ in range(cnt_reload):\n",
    "        onnx_predictions = session.run(None, {input_name: X_test_scaled.astype(np.float32)})\n",
    "    inference_time_onnx = (time.time() - start_time_onnx) / cnt_reload\n",
    "    print(f\"Среднее время инференса ONNX Quant: {inference_time_onnx:.5f} секунд.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
